Learning Resources: <br>
https://www.pinecone.io/learn/vector-embeddings-for-developers/ <br>
https://jalammar.github.io/illustrated-word2vec/ <br>
https://www.pinecone.io/learn/vector-database/ <br>
https://www.gomomento.com/blog/what-is-a-vector-index

# Vector Embeddings
Vector Embedding is actually for a automatic feature engineering. We're using a pretrained model to help us filter the most relevant features.
## Problems trying to solve:
- Over time, the number of properties of objects grows. And for some particular tasks, we don't really need to consider that many properties, we need to do some feature engineering
- For unstructured data, this is more challenging to do it manually
## Intro about Vector Embeddings
-  Why Vectors??? Modern CPUs and GPUs are optimized to perform the mathematical operations needed to process vectors. But a problem is that usually our data is not represented as vectors.
-  It’s a technique that allows us to take virtually any data type and represent it as vectors. Moreover, We want to ensure that we can perform tasks on this transformed data without losing the data’s original meaning.
We want to make sure when we turn data to mathematically vectors, their original meaning and relationships(associations) are well preserved. 
-  We transform data to vectors using an embedding model which is trained in a neural network(supervised training). Instead of inputs to a labeled output, we do inputs to another inputs vector, basically we removed the last layer in the neural network, but we
still do the activation functions, etc.
- An example: 
word2vec: king-man+woman ~= queen  <br>
Details from https://www.pinecone.io/learn/vector-embeddings-for-developers/:  <br>
As we saw with word2vec, within the context of the model, vectors that are close together have a contextual similarity, whereas far-apart vectors are different from one another. That’s what gives our vector meaning — its relationship with other vectors in the vector space depends on how the embedding model “understands” the domain it was trained on.

# Vector Databases
- Why we need it! <br>
Embeddings are generated by AI models (such as Large Language Models) and have many attributes or features, making their representation challenging to manage. We need a specific database to handle this vector data type.
- Vector Intex vs. Vector Database



